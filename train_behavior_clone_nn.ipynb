{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Extract data from the .csv file\"\"\"\n",
    "lines = []\n",
    "with open('./data/driving_log.csv') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "# images and mearsurments will be our input_X and input_y\n",
    "# Augment training set by flip the image horizonaly and flip the sign of mearsurment.\n",
    "augmented_images = []\n",
    "augmented_mearsurements = []\n",
    "for i in range(len(lines)):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    line = lines[i]\n",
    "    for j in range(3):\n",
    "        # source path could be center(0)/left(1)/right(2)\n",
    "        source_path = line[j]\n",
    "        filename = source_path.split('/')[-1]\n",
    "        current_path = './data/IMG/' + filename\n",
    "        image = cv2.imread(current_path)\n",
    "        augmented_images.append(image)\n",
    "        augmented_images.append(cv2.flip(image, 1))\n",
    "        if j == 0:\n",
    "            mearsurement = float(line[3])\n",
    "        elif j == 1:\n",
    "            mearsurement = float(line[3]) + 0.2\n",
    "        elif j == 2:\n",
    "            mearsurement = float(line[3]) - 0.2\n",
    "        augmented_mearsurements.append(mearsurement)\n",
    "        augmented_mearsurements.append(mearsurement * -1.0)\n",
    "\n",
    "\n",
    "# for i in range(len(lines)):\n",
    "#     if i == 0:\n",
    "#         continue\n",
    "#     line = lines[i]\n",
    "#     source_path = line[0]\n",
    "#     filename = source_path.split('/')[-1]\n",
    "#     current_path = './data/IMG/' + filename\n",
    "#     image = cv2.imread(current_path)\n",
    "#     augmented_images.append(image)\n",
    "#     augmented_images.append(cv2.flip(image, 1))\n",
    "#     mearsurement = float(line[3])\n",
    "#     augmented_mearsurements.append(mearsurement)\n",
    "#     augmented_mearsurements.append(mearsurement * -1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48216, 160, 320, 3) (48216,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Set X_train and y_train\"\"\"\n",
    "X_train = np.array(augmented_images)\n",
    "y_train = np.array(augmented_mearsurements)\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  -0.   0.2 -0.2 -0.2  0.2  0.  -0.   0.2 -0.2 -0.2  0.2]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_5 (Lambda)            (None, 160, 320, 3)       0         \n",
      "_________________________________________________________________\n",
      "cropping2d_5 (Cropping2D)    (None, 65, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 31, 158, 24)       1824      \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 14, 77, 36)        21636     \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 5, 37, 48)         43248     \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 3, 35, 64)         27712     \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 1, 33, 64)         36928     \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 2112)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               211300    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 348,219\n",
      "Trainable params: 348,219\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Build a simple regression model\"\"\"\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Conv2D, MaxPooling2D, Cropping2D\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, TensorBoard  \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x / 255.0 - 0.5, input_shape=(160,320,3)))\n",
    "# crop 70 rows of pixels on the top and 25 rows of pixels on the bottom.\n",
    "model.add(Cropping2D(cropping=((70, 25), (0, 0))))\n",
    "model.add(Conv2D(24, (5, 5), activation=\"relu\", strides=(2, 2)))     # subsample: stride\n",
    "# model.add(MaxPooling2D())\n",
    "model.add(Conv2D(36, (5, 5), activation=\"relu\", strides=(2, 2)))\n",
    "# model.add(MaxPooling2D())\n",
    "model.add(Conv2D(48, (5, 5), activation=\"relu\", strides=(2, 2)))\n",
    "# model.add(MaxPooling2D())\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(50))\n",
    "# output regression layer\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-def0842e214f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdatagen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, augment, rounds, seed)\u001b[0m\n\u001b[1;32m    709\u001b[0m             \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcase\u001b[0m \u001b[0mof\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0minput\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m         \"\"\"\n\u001b[0;32m--> 711\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m             raise ValueError('Input to `.fit()` should have rank 4. '\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \"\"\"\n\u001b[0;32m--> 492\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator()\n",
    "datagen.fit(X_train)\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=0, verbose=0, mode='auto')]\n",
    "\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=128), \n",
    "          validation_split=0.2, \n",
    "          shuffle=True, \n",
    "          epochs=10,\n",
    "          callbacks=callbacks)\n",
    "\n",
    "\n",
    "\n",
    "model.save(\"./models/model_aug_3_2e.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
